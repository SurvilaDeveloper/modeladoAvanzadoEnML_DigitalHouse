# ğŸ“Š MÃ©tricas para Evaluar un Modelo de RegresiÃ³n Lineal

---

## 1. MÃ©tricas Basadas en Errores

Estas mÃ©tricas cuantifican la diferencia entre los valores reales \( y_i \) y los valores predichos \( \hat{y}_i \).

### ğŸ”¸ MAE â€” Mean Absolute Error

$$
\text{MAE} = \frac{1}{n} \sum_{i=1}^{n} \left| y_i - \hat{y}_i \right|
$$

- Promedio de errores absolutos.
- Robusta ante valores atÃ­picos.

---

### ğŸ”¸ MSE â€” Mean Squared Error

$$
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$

- Penaliza mÃ¡s los errores grandes.
- No tiene la misma unidad que \( y \).

---

### ğŸ”¸ RMSE â€” Root Mean Squared Error

$$
\text{RMSE} = \sqrt{\text{MSE}} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}
$$

- MSE en las mismas unidades que \( y \).

---

### ğŸ”¸ MAPE â€” Mean Absolute Percentage Error

$$
\text{MAPE} = \frac{100\%}{n} \sum_{i=1}^{n} \left| \frac{y_i - \hat{y}_i}{y_i} \right|
$$

- Error relativo en porcentaje.
- Sensible a valores reales cercanos a cero.

---

### ğŸ”¸ SMAPE â€” Symmetric MAPE

$$
\text{SMAPE} = \frac{100\%}{n} \sum_{i=1}^{n} \frac{|y_i - \hat{y}_i|}{(|y_i| + |\hat{y}_i|)/2}
$$

- VersiÃ³n simÃ©trica del MAPE.
- Estable cuando \( y_i \approx 0 \).

---

## 2. MÃ©tricas Basadas en Varianza Explicada

### ğŸ”¸ RÂ² â€” Coeficiente de DeterminaciÃ³n

$$
R^2 = 1 - \frac{\text{SSE}}{\text{SCT}} = \frac{\text{SSR}}{\text{SCT}}
$$

- Mide la proporciÃ³n de variabilidad explicada por el modelo.
- VarÃ­a entre 0 (malo) y 1 (perfecto).

---

### ğŸ”¸ RÂ² Ajustado

$$
R^2_{adj} = 1 - \left(1 - R^2\right) \cdot \frac{n - 1}{n - k - 1}
$$

- Penaliza por usar variables irrelevantes.
- \( k \): nÃºmero de variables independientes.

---

### ğŸ”¸ SCT â€” Suma Total de los Cuadrados
### ğŸ”¸ TSS - Total Sum of Squares

$$
\text{SCT} = \sum_{i=1}^{n} (y_i - \bar{y})^2
$$

- Mide la variaciÃ³n total en los datos.

---

### ğŸ”¸ SSR â€” Sum of Squares for Regression o Sum of Squares Residual (Suma de los Cuadrados de la RegresiÃ³n)
### ğŸ”¸ ESS - Explained Sum of Squares

$$
\text{SSR} = \sum_{i=1}^{n} (\hat{y}_i - \bar{y})^2
$$

- VariaciÃ³n explicada por el modelo.

---

### ğŸ”¸ SSE â€” Sum of Squared Errors (Suma de los Cuadrados del Error -Residuos-)
### ğŸ”¸ RSS - Residual Sum of Squares

$$
\text{SSE} = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$

- VariaciÃ³n no explicada por el modelo.

---

## 3. MÃ©tricas EstadÃ­sticas

### ğŸ”¸ EstadÃ­stico t

$$
t = \frac{\hat{\beta}_j}{SE(\hat{\beta}_j)}
$$

- EvalÃºa si el coeficiente \( \beta_j \) es significativamente distinto de 0.

---

### ğŸ”¸ p-valor

$$
p = 2 \cdot P(T > |t|)
$$

- Probabilidad de obtener un valor tan extremo como \( t \) bajo la hipÃ³tesis nula.

---

### ğŸ”¸ EstadÃ­stico F

EvalÃºa si al menos una variable independiente tiene un efecto significativo.

$$
F = \frac{\text{SSR} / k}{\text{SSE} / (n - k - 1)}
$$

- \( k \): nÃºmero de predictores.

---

### ğŸ”¸ Prob(F-statistic)

- El p-valor asociado al estadÃ­stico F.
- EvalÃºa la hipÃ³tesis nula: todos los coeficientes \( \beta_i = 0 \).

---

## 4. MÃ©tricas de EvaluaciÃ³n de Residuos

### ğŸ”¸ Durbin-Watson

- EvalÃºa autocorrelaciÃ³n en los residuos.
- Ideal: cercano a 2.

---

### ğŸ”¸ Jarque-Bera

- Prueba de normalidad para los residuos.

---

### ğŸ”¸ Omnibus

- Prueba combinada para normalidad (asimetrÃ­a y curtosis).

---

### ğŸ”¸ Skewness y Kurtosis

- AsimetrÃ­a (skewness): ideal cercano a 0.
- Curtosis: ideal cercano a 3 (normal).

---
